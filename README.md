# TANI Project - AnÃ¡lisis de Desarrollo Infantil

Este proyecto implementa un pipeline de procesamiento de datos y anÃ¡lisis para la ONG TANI, enfocado en predecir riesgos de dÃ©ficit en el desarrollo infantil (lenguaje, social, cognitivo, motor) basÃ¡ndose en datos histÃ³ricos de controles de salud.

## ğŸš€ Requisitos Previos

Este proyecto utiliza **[uv](https://github.com/astral-sh/uv)** para la gestiÃ³n de dependencias y entornos virtuales, lo que garantiza una ejecuciÃ³n rÃ¡pida y reproducible.

1.  **Instalar uv**:
    ```bash
    # macOS / Linux
    curl -LsSf https://astral.sh/uv/install.sh | sh
    ```

## ğŸ“¦ InstalaciÃ³n

Una vez instalado `uv`, clona este repositorio y sincroniza las dependencias:

```bash
# Instalar dependencias definidas en pyproject.toml
uv sync
```

## ğŸ“‚ Estructura del Proyecto

```text
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Archivos Excel originales (DATA PROYECTO BREIT.xlsx, etc.)
â”‚   â””â”€â”€ processed/      # Datasets generados por el pipeline
â”œâ”€â”€ notebooks/          # Notebooks de exploraciÃ³n (Jupyter/Quarto)
â”œâ”€â”€ reports/            # Reportes generados y figuras
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/         # Configuraciones y rutas (settings.py)
â”‚   â”œâ”€â”€ data/           # Scripts de limpieza y carga
â”‚   â”œâ”€â”€ features/       # IngenierÃ­a de caracterÃ­sticas (build_features.py)
â”‚   â”œâ”€â”€ pipelines/      # Scripts de ejecuciÃ³n (01_preprocessing.py, 02_eda.py)
â”‚   â””â”€â”€ visualization/  # Funciones de ploteo
â””â”€â”€ pyproject.toml      # DefiniciÃ³n de dependencias
```

## âš™ï¸ EjecuciÃ³n de Pipelines

El proyecto estÃ¡ modularizado en pipelines que se ejecutan con `uv run`.

### 1. Preprocesamiento y Feature Engineering

Este pipeline carga los datos crudos, limpia, genera features (ventanas histÃ³ricas, anemia, nutriciÃ³n) y crea los datasets finales.

```bash
uv run src/pipelines/01_preprocessing.py
```

**Salidas generadas en `data/processed/`:**
*   `tani_analytical_dataset.csv`: Dataset longitudinal completo (historia de controles).
*   `tani_patient_features.csv`: Dataset a nivel paciente con features agregados.
*   `tani_model_ready.csv`: **Dataset final para modelado** (limpio, imputado y sin columnas constantes).

### 2. AnÃ¡lisis Exploratorio de Datos (EDA)

Genera visualizaciones automÃ¡ticas basadas en el dataset listo para modelar.

```bash
uv run src/pipelines/02_eda.py
```

**Salidas generadas en `reports/figures/`:**
*   `eda_histograms_model_ready.png`: Histogramas de las variables numÃ©ricas.
*   `eda_histograms_by_deficit.png`: ComparaciÃ³n de distribuciones segÃºn el target `deficit`.

### 3. Modelado Predictivo y OptimizaciÃ³n
Entrena y evalÃºa modelos de Machine Learning (Logistic Regression, Random Forest, XGBoost, LightGBM).
*   **OptimizaciÃ³n**: Para cada algoritmo, entrena una versiÃ³n Baseline y una Optimizada (`RandomizedSearchCV`).
*   **SelecciÃ³n**: Elige automÃ¡ticamente el mejor modelo basado en AUC.
*   **Interpretabilidad**: Genera grÃ¡ficos SHAP del modelo ganador.

```bash
uv run src/pipelines/03_modeling.py
```

**Salidas generadas en `reports/`:**
*   `model_comparison.csv`: Tabla comparativa de mÃ©tricas (AUC, Precision, Recall, F1).
*   `figures/modeling/`: GrÃ¡ficos de evaluaciÃ³n (Matrices de ConfusiÃ³n, Curvas ROC, Feature Importance).
*   `figures/interpretability/`: **AnÃ¡lisis SHAP** del mejor modelo (Summary Plot, Global Importance).

## ğŸ“Š Diccionario de Datos (Salidas)

Para un detalle completo de cada variable, consulta el [Diccionario de Datos](references/data_dictionary.md).

| Archivo | DescripciÃ³n | Uso Principal |
| :--- | :--- | :--- |
| **`tani_model_ready.csv`** | Una fila por paciente. Contiene features de ventana (Ãºltimos 6 controles), features del primer aÃ±o de vida, e intensidad de consejerÃ­a. Sin nulos. | **Entrenamiento de Modelos** |
| `tani_patient_features.csv` | Igual que el anterior pero sin imputaciÃ³n de nulos y con todas las columnas generadas. | AnÃ¡lisis detallado / Debugging |
| `tani_analytical_dataset.csv` | Dataset transaccional (una fila por control). Contiene la historia completa dÃ­a a dÃ­a. | AnÃ¡lisis de series de tiempo / Deep Learning |

*   `0`: El paciente no presentÃ³ dÃ©ficits.

## ğŸ§  MetodologÃ­a de Modelamiento

El pipeline de modelado (`src/pipelines/03_modeling.py`) sigue un enfoque riguroso para garantizar robustez y explicabilidad:

### 1. SelecciÃ³n de Variables (`src/features/selection.py`)
Antes del entrenamiento, se seleccionan las variables mÃ¡s relevantes para reducir ruido y dimensionalidad:
*   **Information Value (IV)**: Se descartan variables con bajo poder predictivo (IV < 0.02).
*   **Filtro de CorrelaciÃ³n**: Se eliminan variables redundantes con correlaciÃ³n > 0.9.
*   **Importancia Base**: Se utiliza un Random Forest preliminar para validar la importancia.

### 2. PreparaciÃ³n de Datos
*   **Split**: DivisiÃ³n estratificada 80/20 (Train/Test).
*   **ImputaciÃ³n**: Mediana para valores faltantes.
*   **Escalamiento**: `StandardScaler` para normalizar features.
*   **Balanceo**: `SMOTE` aplicado solo al conjunto de entrenamiento para manejar el desbalance de clases (~3% de casos positivos).

### 3. Entrenamiento y OptimizaciÃ³n (`src/models/train_model.py`)
Se entrenan 4 algoritmos, cada uno con dos estrategias:
*   **Algoritmos**: Logistic Regression, Random Forest, XGBoost, LightGBM.
*   **Estrategias**:
    1.  **Baseline**: HiperparÃ¡metros por defecto.
    2.  **Optimized**: BÃºsqueda aleatoria (`RandomizedSearchCV`) con validaciÃ³n cruzada estratificada (3-fold).
*   **Total**: 8 modelos candidatos compiten por el mejor AUC.

### 4. EvaluaciÃ³n e Interpretabilidad (`src/models/interpretability.py`)
*   **SelecciÃ³n**: El modelo con mayor AUC en el set de prueba es declarado ganador.
*   **SHAP (SHapley Additive exPlanations)**: Se calculan los valores SHAP del modelo ganador para explicar:
    *   **Impacto Global**: QuÃ© variables influyen mÃ¡s en la predicciÃ³n.
    *   **Direccionalidad**: CÃ³mo valores altos/bajos de una variable afectan la probabilidad de riesgo.
