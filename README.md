# TANI Project - An√°lisis de Desarrollo Infantil

Este proyecto implementa un pipeline de procesamiento de datos y an√°lisis para la ONG TANI, enfocado en predecir riesgos de d√©ficit en el desarrollo infantil (lenguaje, social, cognitivo, motor) bas√°ndose en datos hist√≥ricos de controles de salud.

## üöÄ Requisitos Previos

Este proyecto utiliza **[uv](https://github.com/astral-sh/uv)** para la gesti√≥n de dependencias y entornos virtuales, lo que garantiza una ejecuci√≥n r√°pida y reproducible.

1.  **Instalar uv**:
    ```bash
    # macOS / Linux
    curl -LsSf https://astral.sh/uv/install.sh | sh
    ```

## üì¶ Instalaci√≥n

Una vez instalado `uv`, clona este repositorio y sincroniza las dependencias:

```bash
# Instalar dependencias definidas en pyproject.toml
uv sync
```

## üìÇ Estructura del Proyecto

```text
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Archivos Excel originales (DATA PROYECTO BREIT.xlsx, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # Datasets generados por el pipeline
‚îÇ   ‚îî‚îÄ‚îÄ external/         # Tablas OMS para c√°lculo de z-scores
‚îú‚îÄ‚îÄ notebooks/            # Notebooks ejecutables de an√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda_comprehensive.qmd       # An√°lisis exploratorio profundo
‚îÇ   ‚îî‚îÄ‚îÄ 02_model_evaluation.qmd        # Evaluaci√≥n de modelos y fairness
‚îú‚îÄ‚îÄ reports/              # Reportes finales y figuras
‚îÇ   ‚îú‚îÄ‚îÄ final_report.qmd  # Reporte final del proyecto (MIT)
‚îÇ   ‚îú‚îÄ‚îÄ final_report.pdf  # PDF generado
‚îÇ   ‚îî‚îÄ‚îÄ figures/          # Visualizaciones (EDA, modeling, interpretability)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config/           # Configuraciones y rutas (settings.py)
‚îÇ   ‚îú‚îÄ‚îÄ data/             # Scripts de limpieza y carga
‚îÇ   ‚îú‚îÄ‚îÄ features/         # Ingenier√≠a de caracter√≠sticas (build_features.py, oms_zscores.py)
‚îÇ   ‚îú‚îÄ‚îÄ models/           # Entrenamiento, evaluaci√≥n e interpretabilidad
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/        # Scripts de ejecuci√≥n secuencial
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_preprocessing.py  # Consolidaci√≥n y limpieza
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_eda.py            # An√°lisis exploratorio b√°sico
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 03_modeling.py       # Entrenamiento de modelos
‚îÇ   ‚îî‚îÄ‚îÄ visualization/    # Funciones de ploteo
‚îú‚îÄ‚îÄ docs/                 # Documentaci√≥n del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ rubrica.jpeg      # R√∫brica de evaluaci√≥n MIT
‚îÇ   ‚îî‚îÄ‚îÄ ejemplo_reporte.md # Ejemplo de reporte anterior
‚îú‚îÄ‚îÄ CLAUDE.md             # Documentaci√≥n para Claude Code (gu√≠a del proyecto)
‚îî‚îÄ‚îÄ pyproject.toml        # Definici√≥n de dependencias
```

## ‚öôÔ∏è Ejecuci√≥n de Pipelines

El proyecto est√° modularizado en pipelines que se ejecutan con `uv run`.

### 1. Preprocesamiento y Feature Engineering

Este pipeline carga los datos crudos, limpia, genera features (ventanas hist√≥ricas, anemia, nutrici√≥n) y crea los datasets finales.

```bash
uv run src/pipelines/01_preprocessing.py
```

**Salidas generadas en `data/processed/`:**
*   `tani_analytical_dataset.csv`: Dataset longitudinal completo (historia de controles).
*   `tani_patient_features.csv`: Dataset a nivel paciente con features agregados.
*   `tani_model_ready.csv`: **Dataset final para modelado** (limpio, imputado y sin columnas constantes).

### 2. An√°lisis Exploratorio de Datos (EDA)

Genera visualizaciones autom√°ticas basadas en el dataset listo para modelar.

```bash
uv run src/pipelines/02_eda.py
```

**Salidas generadas en `reports/figures/`:**
*   `eda_histograms_model_ready.png`: Histogramas de las variables num√©ricas.
*   `eda_histograms_by_deficit.png`: Comparaci√≥n de distribuciones seg√∫n el target `deficit`.

### 3. Modelado Predictivo y Optimizaci√≥n
Entrena y eval√∫a modelos de Machine Learning (Logistic Regression, Random Forest, XGBoost, LightGBM).
*   **Optimizaci√≥n**: Para cada algoritmo, entrena una versi√≥n Baseline y una Optimizada (`RandomizedSearchCV`).
*   **Selecci√≥n**: Elige autom√°ticamente el mejor modelo basado en AUC.
*   **Interpretabilidad**: Genera gr√°ficos SHAP del modelo ganador.

```bash
uv run src/pipelines/03_modeling.py
```

**Salidas generadas en `reports/`:**
*   `model_comparison.csv`: Tabla comparativa de m√©tricas (AUC, Precision, Recall, F1).
*   `figures/modeling/`: Gr√°ficos de evaluaci√≥n (Matrices de Confusi√≥n, Curvas ROC, Feature Importance).
*   `figures/interpretability/`: **An√°lisis SHAP** del mejor modelo (Summary Plot, Global Importance).

### 4. Validaci√≥n Temporal (Out-of-Time Validation)
Eval√∫a los modelos en un conjunto de test **temporal** (pacientes observados en periodos futuros).
*   **Split Temporal**: 80% entrenamiento (hasta Junio 2025), 20% test (despu√©s Junio 2025).
*   **Evaluaci√≥n**: Compara rendimiento en test aleatorio vs test temporal.
*   **Degradaci√≥n**: Mide ca√≠da de performance en datos futuros (drift temporal).

```bash
uv run src/pipelines/04_temporal_validation.py
```

**Salidas generadas en `reports/`:**
*   `model_comparison_temporal.csv`: M√©tricas en test set temporal.
*   `model_comparison_random_vs_temporal.csv`: Comparaci√≥n de degradaci√≥n entre test aleatorio y temporal.

**Hallazgos Clave**:
*   Random Forest Optimized: 6.4% degradaci√≥n (AUC 0.810 ‚Üí 0.758)
*   Logistic Regression: 5.6% degradaci√≥n (m√°s estable temporalmente)
*   XGBoost: 22.3% degradaci√≥n (posible overfitting)

### 5. Interpretabilidad Avanzada (SHAP Comprehensivo)
Genera visualizaciones avanzadas de SHAP para interpretar el modelo ganador.
*   **Gr√°ficos Globales**: Summary plot, bar plot de importancia
*   **Casos Individuales**: Waterfall plots (alto/bajo riesgo), force plots
*   **Relaciones No-Lineales**: Dependence plots para top 6 features
*   **Interacciones**: Interaction plot entre top 2 features
*   **Patrones**: Heatmap de SHAP values (30 casos √ó 15 features)

```bash
uv run src/pipelines/05_advanced_interpretability.py
```

**Salidas generadas en `reports/figures/interpretability/`:**
*   `shap_summary.png`, `shap_importance.png`: Importancia global
*   `shap_waterfall_high_risk.png`, `shap_waterfall_low_risk.png`: Explicaciones individuales
*   `shap_dependence_1_*.png` a `shap_dependence_6_*.png`: Dependence plots
*   `shap_interaction_top2.png`: Interacci√≥n entre top 2 features
*   `shap_heatmap.png`: Patrones de SHAP values
*   `shap_force_high_risk.png`: Force plot caso alto riesgo
*   `shap_statistics.csv`: Estad√≠sticas de SHAP por feature
*   `shap_feature_directions.csv`: An√°lisis de direccionalidad

**Insights Clave**:
*   **Intensidad de consejer√≠a**: Efecto protector fuerte (SHAP: -0.023)
*   **Edad m√°xima en ventana**: Mayor edad = menor riesgo (SHAP: -0.019)
*   **Consejer√≠a en vacunas**: Proxy de engagement parental (SHAP: -0.022)
*   **Threshold cr√≠tico**: 5+ sesiones de consejer√≠a para protecci√≥n √≥ptima

---

## üìì Notebooks de An√°lisis Comprehensivo

El proyecto incluye notebooks ejecutables en formato **Quarto** (`.qmd`) para an√°lisis profundo y reproducible.

### 1. EDA Comprehensivo (`notebooks/01_eda_comprehensive.qmd`)

An√°lisis exploratorio riguroso alineado con est√°ndares acad√©micos (MIT):

**Contenido:**
*   **Data Quality Assessment**: An√°lisis de valores faltantes, outliers, distribuciones
*   **Univariate Analysis**: Estad√≠sticas descriptivas robustas (media, mediana, skewness, kurtosis)
*   **Bivariate Analysis**: Correlaciones, tests estad√≠sticos (Mann-Whitney U, Chi-cuadrado)
*   **Subgroup Analysis**: An√°lisis estratificado por edad y sexo
*   **Advanced Visualizations**: Violin plots, pairplots, correlation heatmaps, mutual information

**Ejecuci√≥n:**
```bash
# Renderizar a HTML
quarto render notebooks/01_eda_comprehensive.qmd
```

**Salidas:**
*   `notebooks/01_eda_comprehensive.html`: Reporte HTML interactivo
*   `reports/figures/`: Gr√°ficos avanzados (pairplots, heatmaps, boxplots, etc.)

### 2. Evaluaci√≥n de Modelos y Fairness (`notebooks/02_model_evaluation.qmd`)

Evaluaci√≥n rigurosa de robustez, estabilidad y equidad del modelo:

**Contenido:**
*   **Experimental Design**: Documentaci√≥n de estrategia de split, cross-validation, manejo de desbalance
*   **Robustness Analysis**:
    - Learning curves (tama√±o de datos vs performance)
    - Cross-validation stability (15 folds √ó 3 repeticiones)
    - Performance segmentado por edad
*   **Fairness Evaluation**:
    - An√°lisis de equidad por sexo (AUC parity, precision parity)
    - Trade-off precision-recall
*   **Ethical Considerations**: Costos de errores, limitaciones, recomendaciones de deployment

**Ejecuci√≥n:**
```bash
# Renderizar a HTML
quarto render notebooks/02_model_evaluation.qmd
```

**Salidas:**
*   `notebooks/02_model_evaluation.html`: Reporte de evaluaci√≥n completo
*   `reports/figures/modeling/`: Learning curves, stability plots, fairness comparisons

---

### 3. Reporte Final MIT (`reports/final_report.qmd`)

Reporte consolidado para entrega al MIT, integrando todos los an√°lisis:

**Contenido:**
*   Executive Summary con hallazgos clave
*   Introducci√≥n y contexto (TANI, desarrollo infantil, objetivos)
*   Data Consolidation (pipeline de limpieza)
*   **EDA Summary** (con referencias a notebook 01)
*   Modeling Methodology y Feature Selection
*   **Model Results** (comparaci√≥n de 8 modelos)
*   **Robustness & Fairness Analysis** (con referencias a notebook 02)
*   Ethical Considerations & Limitations
*   Conclusions & Recommendations (12 recomendaciones accionables)
*   References y Appendices

**Renderizado a PDF:**
```bash
# Generar PDF final para entrega
quarto render reports/final_report.qmd --to pdf
```

**Salida:**
*   `reports/final_report.pdf`: Reporte final listo para entrega MIT

---

## üìä Diccionario de Datos (Salidas)

Para un detalle completo de cada variable, consulta el [Diccionario de Datos](references/data_dictionary.md).

| Archivo | Descripci√≥n | Uso Principal |
| :--- | :--- | :--- |
| **`tani_model_ready.csv`** | Una fila por paciente. Contiene features de ventana (√∫ltimos 6 controles), features del primer a√±o de vida, e intensidad de consejer√≠a. Sin nulos. | **Entrenamiento de Modelos** |
| `tani_patient_features.csv` | Igual que el anterior pero sin imputaci√≥n de nulos y con todas las columnas generadas. | An√°lisis detallado / Debugging |
| `tani_analytical_dataset.csv` | Dataset transaccional (una fila por control). Contiene la historia completa d√≠a a d√≠a. | An√°lisis de series de tiempo / Deep Learning |

*   `0`: El paciente no present√≥ d√©ficits.

## üß† Metodolog√≠a de Modelamiento

El pipeline de modelado (`src/pipelines/03_modeling.py`) sigue un enfoque riguroso para garantizar robustez y explicabilidad:

### 1. Selecci√≥n de Variables (`src/features/selection.py`)
Antes del entrenamiento, se seleccionan las variables m√°s relevantes para reducir ruido y dimensionalidad:
*   **Information Value (IV)**: Se descartan variables con bajo poder predictivo (IV < 0.02).
*   **Filtro de Correlaci√≥n**: Se eliminan variables redundantes con correlaci√≥n > 0.9.
*   **Importancia Base**: Se utiliza un Random Forest preliminar para validar la importancia.

### 2. Preparaci√≥n de Datos
*   **Split**: Divisi√≥n estratificada 80/20 (Train/Test).
*   **Imputaci√≥n**: Mediana para valores faltantes.
*   **Escalamiento**: `StandardScaler` para normalizar features.
*   **Balanceo**: `SMOTE` aplicado solo al conjunto de entrenamiento para manejar el desbalance de clases (~3% de casos positivos).

### 3. Entrenamiento y Optimizaci√≥n (`src/models/train_model.py`)
Se entrenan 4 algoritmos, cada uno con dos estrategias:
*   **Algoritmos**: Logistic Regression, Random Forest, XGBoost, LightGBM.
*   **Estrategias**:
    1.  **Baseline**: Hiperpar√°metros por defecto.
    2.  **Optimized**: B√∫squeda aleatoria (`RandomizedSearchCV`) con validaci√≥n cruzada estratificada (3-fold).
*   **Total**: 8 modelos candidatos compiten por el mejor AUC.

### 4. Evaluaci√≥n e Interpretabilidad (`src/models/interpretability.py`)
*   **Selecci√≥n**: El modelo con mayor AUC en el set de prueba es declarado ganador.
*   **SHAP (SHapley Additive exPlanations)**: Se calculan los valores SHAP del modelo ganador para explicar:
    *   **Impacto Global**: Qu√© variables influyen m√°s en la predicci√≥n.
    *   **Direccionalidad**: C√≥mo valores altos/bajos de una variable afectan la probabilidad de riesgo.
